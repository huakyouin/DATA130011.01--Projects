{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note：此文件用对8个novel对象的测试集进行评测**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算指标,如遇问题请进入MyEval.py文件修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:__main__:\n",
      "*****************************************\n",
      "Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "*****************************************\n",
      "| distributed init (rank 3, word 4): env://eval\n",
      "| distributed init (rank 1, word 4): env://eval\n",
      "| distributed init (rank 2, word 4): env://eval\n",
      "| distributed init (rank 0, word 4): env://eval\n",
      "Creating model..\n",
      "use my model!\n",
      "1..\n",
      "2..\n",
      "load checkpoint from output/Caption_coco_DCC_pretrain_1/checkpoint_best.pth\n",
      "3..\n",
      "model created!\n",
      "Creating captioning dataset\n",
      "Start evaluating  captions_split_set_bottle_val_test_novel2014.json ..\n",
      "Caption generation:  [ 0/10]  eta: 0:01:42    time: 10.2136  data: 2.1445  max mem: 3037\n",
      "Caption generation:  [ 9/10]  eta: 0:00:03    time: 3.6274  data: 0.2146  max mem: 3037\n",
      "Caption generation: Total time: 0:00:36 (3.6458 s / it)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"MyEval.py\", line 179, in <module>\n",
      "  File \"MyEval.py\", line 179, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"MyEval.py\", line 179, in <module>\n",
      "            \n",
      "\n",
      "  File \"MyEval.py\", line 119, in main\n",
      "  File \"MyEval.py\", line 119, in main\n",
      "\n",
      "  File \"MyEval.py\", line 119, in main\n",
      "        coco_test = coco_caption_DCC_eval(config['ann_root_DCC'],test_result_file,'test',coco_test = coco_caption_DCC_eval(config['ann_root_DCC'],test_result_file,'test',\n",
      "\n",
      "  File \"/home/newdisk/jxh/课程项目/神网PJ_3/BLIP-main/data/utils.py\", line 123, in coco_caption_DCC_eval\n",
      "  File \"/home/newdisk/jxh/课程项目/神网PJ_3/BLIP-main/data/utils.py\", line 123, in coco_caption_DCC_eval\n",
      "    coco_test = coco_caption_DCC_eval(config['ann_root_DCC'],test_result_file,'test',\n",
      "  File \"/home/newdisk/jxh/课程项目/神网PJ_3/BLIP-main/data/utils.py\", line 123, in coco_caption_DCC_eval\n",
      "        coco_result = coco.loadRes(results_file)coco_result = coco.loadRes(results_file)\n",
      "\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/pycocotools/coco.py\", line 320, in loadRes\n",
      "      File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/pycocotools/coco.py\", line 320, in loadRes\n",
      "coco_result = coco.loadRes(results_file)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/pycocotools/coco.py\", line 320, in loadRes\n",
      "        anns = json.load(f)anns = json.load(f)\n",
      "\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/__init__.py\", line 293, in load\n",
      "      File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/__init__.py\", line 293, in load\n",
      "anns = json.load(f)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/__init__.py\", line 293, in load\n",
      "    return loads(fp.read(),\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "        return loads(fp.read(),return loads(fp.read(),\n",
      "\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/__init__.py\", line 357, in loads\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    return _default_decoder.decode(s)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/decoder.py\", line 337, in decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/json/decoder.py\", line 355, in raw_decode\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError:     Expecting value: line 1 column 1 (char 0)raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "    raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n",
      "json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n",
      "result file saved to output/DCC_eval/result/bottle_predict.json\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "tokenization...\n",
      "PTBTokenizer tokenized 16484 tokens at 133302.38 tokens per second.\n",
      "PTBTokenizer tokenized 2841 tokens at 25533.67 tokens per second.\n",
      "setting up scorers...\n",
      "computing Bleu score...\n",
      "{'testlen': 2581, 'reflen': 2550, 'guess': [2581, 2331, 2081, 1831], 'correct': [2040, 1153, 571, 270]}\n",
      "ratio: 1.012156862744701\n",
      "Bleu_1: 0.790\n",
      "Bleu_2: 0.625\n",
      "Bleu_3: 0.475\n",
      "Bleu_4: 0.355\n",
      "computing METEOR score...\n",
      "WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 90184 closing signal SIGTERM\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 90185) of binary: /home/newdisk/jxh/anaconda/envs/blip/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/runpy.py\", line 87, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/torch/distributed/run.py\", line 723, in <module>\n",
      "    main()\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 345, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/torch/distributed/run.py\", line 719, in main\n",
      "    run(args)\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/torch/distributed/run.py\", line 710, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 131, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/newdisk/jxh/anaconda/envs/blip/lib/python3.8/site-packages/torch/distributed/launcher/api.py\", line 259, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "MyEval.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2022-05-27_17:37:08\n",
      "  host      : dbcloud\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 90186)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "[2]:\n",
      "  time      : 2022-05-27_17:37:08\n",
      "  host      : dbcloud\n",
      "  rank      : 3 (local_rank: 3)\n",
      "  exitcode  : 1 (pid: 90187)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2022-05-27_17:37:08\n",
      "  host      : dbcloud\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 1 (pid: 90185)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "! python -m torch.distributed.run --nproc_per_node=4 MyEval.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1得分计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.80s)\n",
      "creating index...\n",
      "index created!\n",
      "----- keyword: couch -----\n",
      "tp: 22, fp: 106, fn: 9, F1_score: 0.277\n",
      "-------------------------\n",
      "----- keyword: microwave -----\n",
      "tp: 16, fp: 24, fn: 2, F1_score: 0.552\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "import json\n",
    "from json import encoder\n",
    "import pandas as pd\n",
    "encoder.FLOAT_REPR = lambda o: format(o, '.3f')\n",
    "\n",
    "def eval_f1(keyword,pred,gt):\n",
    "    tp=0;fp=0;fn=0\n",
    "    df1=pd.DataFrame(pred)\n",
    "    df2=pd.DataFrame(gt)\n",
    "    for index in range(len(df1)):\n",
    "        id=df1.loc[index].image_id\n",
    "        pred_cap=df1.loc[index].caption\n",
    "        pred_positive=True if pred_cap.find(keyword)!= -1 else False\n",
    "        temp=df2[df2.image_id==id]\n",
    "        len1=len(temp)\n",
    "        temp=temp[temp.caption.str.contains(keyword)]\n",
    "        if pred_positive and len(temp)==len1: tp+=1\n",
    "        if pred_positive and len(temp)!=len1: fp+=1\n",
    "        if not pred_positive and len(temp)==len1: fn+=1\n",
    "    \n",
    "    print('-'*5,'keyword:',keyword,'-'*5)\n",
    "    print('tp: %d, fp: %d, fn: %d, F1_score: %.3f'%(tp,fp,fn,tp/(tp+0.5*fp+0.5*fn)))\n",
    "    print('-'*25) \n",
    "\n",
    "\n",
    "ann_file=\"annotation/DCC/captions_val_test2014.json\" \n",
    "# ground_truth\n",
    "annFile= ann_file\n",
    "coco = COCO(annFile)\n",
    "gt = coco.dataset['annotations']\n",
    "group1=['bottle','bus','couch','microwave','pizza','racket','suitcase','zebra']\n",
    "group2=['couch','microwave']\n",
    "\n",
    "for name in group2:\n",
    "    pred_file='output/DCC_eval/result/%s_predict.json' %name\n",
    "    # prediction\n",
    "    with open(pred_file, 'rb') as f:\n",
    "        pred = json.load(f)\n",
    "    eval_f1(name,pred,gt)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "003f6c9cdbb02572fb1790fd746af9ef5b3ec9c1f8234847c0ea4a164fd6a9c0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('blip': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
